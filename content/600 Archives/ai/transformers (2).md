---
date: 2024-08-21
category:
  - topic
---
**Concept**: The backbone of modern AI language models. 

**Publication**: "Attention Is All You Need" by Google in 2017 

**Significance**: Revolutionized machine translation and question answering.

Transformers are machine learning models that process entire sequences of text at once, understanding connections between words. 
## Examples 
- **BERT**: Bidirectional Encoder Representations from Transformers. 
- **[[gpt]]**: Generative Pre-trained Transformer.