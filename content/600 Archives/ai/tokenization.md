---
date: 2024-08-21
category:
  - topic
---
Tokenization involves converting text into numerical representations, called tokens, used by models like GPT-3.

## Example
- **Text**: "Hello, how are you?"
- **Tokens**: "Hello", ",", "how", "are", "you", "?"

[[nlp-workflow#NLP Applications]]